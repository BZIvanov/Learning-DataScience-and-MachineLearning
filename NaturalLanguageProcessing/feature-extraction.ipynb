{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e158548",
   "metadata": {},
   "source": [
    "# Feature extraction from text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff63f1b",
   "metadata": {},
   "source": [
    "## Part 1: Manual feature extraction (without using libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd2e2a",
   "metadata": {},
   "source": [
    "The files will contain very simple textx without any punctuation to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01386073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eca332f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'animals',\n",
       " 'are',\n",
       " 'canine',\n",
       " 'dogs',\n",
       " 'furry',\n",
       " 'is',\n",
       " 'our',\n",
       " 'pets',\n",
       " 'story',\n",
       " 'this'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_one = \"This is a story about dogs our canine pets Dogs are furry animals\".lower().split()\n",
    "unique_words_one = set(words_one)\n",
    "    \n",
    "unique_words_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "983a9a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'catching',\n",
       " 'fun',\n",
       " 'is',\n",
       " 'popular',\n",
       " 'sport',\n",
       " 'story',\n",
       " 'surfing',\n",
       " 'this',\n",
       " 'water',\n",
       " 'waves'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_two = \"This story is about surfing Catching waves is fun Surfing is a popular water sport\".lower().split()\n",
    "unique_words_two = set(words_two)\n",
    "    \n",
    "unique_words_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc336ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'animals',\n",
       " 'are',\n",
       " 'canine',\n",
       " 'catching',\n",
       " 'dogs',\n",
       " 'fun',\n",
       " 'furry',\n",
       " 'is',\n",
       " 'our',\n",
       " 'pets',\n",
       " 'popular',\n",
       " 'sport',\n",
       " 'story',\n",
       " 'surfing',\n",
       " 'this',\n",
       " 'water',\n",
       " 'waves'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_unique_words = set()\n",
    "all_unique_words.update(unique_words_one)\n",
    "all_unique_words.update(unique_words_two)\n",
    "\n",
    "all_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9ffb082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'furry': 0,\n",
       " 'water': 1,\n",
       " 'is': 2,\n",
       " 'animals': 3,\n",
       " 'story': 4,\n",
       " 'about': 5,\n",
       " 'are': 6,\n",
       " 'waves': 7,\n",
       " 'surfing': 8,\n",
       " 'our': 9,\n",
       " 'catching': 10,\n",
       " 'dogs': 11,\n",
       " 'pets': 12,\n",
       " 'this': 13,\n",
       " 'fun': 14,\n",
       " 'sport': 15,\n",
       " 'canine': 16,\n",
       " 'a': 17,\n",
       " 'popular': 18}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_vocab = dict()\n",
    "i = 0\n",
    "\n",
    "for word in all_unique_words:\n",
    "    full_vocab[word] = i\n",
    "    i = i + 1\n",
    "    \n",
    "full_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44cf51d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "one_freq = [0] * len(full_vocab)\n",
    "two_freq = [0] * len(full_vocab)\n",
    "all_words = [''] * len(full_vocab)\n",
    "\n",
    "print(one_freq)\n",
    "print(two_freq)\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b31c9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 2, 1, 1, 0, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_text = \"This is a story about dogs our canine pets Dogs are furry animals\".lower().split()\n",
    "    \n",
    "for word in one_text:\n",
    "    word_ind = full_vocab[word]\n",
    "    one_freq[word_ind] += 1\n",
    "    \n",
    "one_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8597e77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 0, 1, 1, 0, 1, 2, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_text = \"This story is about surfing Catching waves is fun Surfing is a popular water sport\".lower().split()\n",
    "    \n",
    "for word in two_text:\n",
    "    word_ind = full_vocab[word]\n",
    "    two_freq[word_ind] += 1\n",
    "\n",
    "two_freq    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d3a4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in full_vocab:\n",
    "    word_ind = full_vocab[word]\n",
    "    all_words[word_ind] = word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b878b0b",
   "metadata": {},
   "source": [
    "Now we have our **Bag of words** below (our dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24cad945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>furry</th>\n",
       "      <th>water</th>\n",
       "      <th>is</th>\n",
       "      <th>animals</th>\n",
       "      <th>story</th>\n",
       "      <th>about</th>\n",
       "      <th>are</th>\n",
       "      <th>waves</th>\n",
       "      <th>surfing</th>\n",
       "      <th>our</th>\n",
       "      <th>catching</th>\n",
       "      <th>dogs</th>\n",
       "      <th>pets</th>\n",
       "      <th>this</th>\n",
       "      <th>fun</th>\n",
       "      <th>sport</th>\n",
       "      <th>canine</th>\n",
       "      <th>a</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   furry  water  is  animals  story  about  are  waves  surfing  our  \\\n",
       "0      1      0   1        1      1      1    1      0        0    1   \n",
       "1      0      1   3        0      1      1    0      1        2    0   \n",
       "\n",
       "   catching  dogs  pets  this  fun  sport  canine  a  popular  \n",
       "0         0     2     1     1    0      0       1  1        0  \n",
       "1         1     0     0     1    1      1       0  1        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=[one_freq, two_freq], columns=all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cedd992",
   "metadata": {},
   "source": [
    "By comparing the vectors we see that some words are common for both files and some are not. Extending this logic to tens of thousands of documents, we would see the vocabulary dictionary grow to hundreds of thousands of words. Vectors would contain mostly zero values, making them sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79e627",
   "metadata": {},
   "source": [
    "### Bag of Words and Tf-idf\n",
    "\n",
    "In the above examples, each vector can be considered a bag of words. By itself these may not be helpful until we consider **term frequencies**, or how often individual words appear in documents. A simple way to calculate term frequencies is to divide the number of occurrences of a word by the total number of words in the document. In this way the number of times a word appears in large documents can be compared to that of smaller documents.\n",
    "\n",
    "It may be hard to differentiate documents based on term frequency if a word shows up in a majority of documents. To handle this we also consider inverse document frequency, which is the total number of documents divided by the number of documents that contain the word. In practice we convert this value to a logarithmic scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d089c71",
   "metadata": {},
   "source": [
    "### Stop Words and Word Stems\n",
    "\n",
    "Some words like \"the\" and \"and\" appear so frequently and in so many documents, that we needn't bother counting them. Also, it may make sense to only record the root of a word, say cat in place of both cat and cats. This will shrink our vocab array and improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6bf50e",
   "metadata": {},
   "source": [
    "## Part 2: Feature extraction with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "742a7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"This is a line\", \"This is another line\", \"Completely different line\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde18bf2",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16296c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395059e",
   "metadata": {},
   "source": [
    "All words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd8bdd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 1, 1, 1],\n",
       "        [1, 0, 0, 1, 1, 1],\n",
       "        [0, 1, 1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "sparse_matrix = cv.fit_transform(text)\n",
    "sparse_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "327de77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 5, 'is': 3, 'line': 4, 'another': 0, 'completely': 1, 'different': 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4fce41",
   "metadata": {},
   "source": [
    "Without stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e33fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be26123f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix = cv.fit_transform(text)\n",
    "sparse_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1be09b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'line': 2, 'completely': 0, 'different': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6284919",
   "metadata": {},
   "source": [
    "### TfidfTransformer\n",
    "\n",
    "TfidfVectorizer is used on sentences, while TfidfTransformer is used on an existing count matrix, such as one returned by CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31b61407",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e1f0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47c0ae91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix = cv.fit_transform(text)\n",
    "sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a70945d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.61980538, 0.48133417,\n",
       "         0.61980538],\n",
       "        [0.63174505, 0.        , 0.        , 0.4804584 , 0.37311881,\n",
       "         0.4804584 ],\n",
       "        [0.        , 0.65249088, 0.65249088, 0.        , 0.38537163,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = tfidf_transformer.fit_transform(sparse_matrix)\n",
    "tfidf.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f62e2",
   "metadata": {},
   "source": [
    "### TfIdfVectorizer\n",
    "\n",
    "Does both above in a single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dd29210",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "445dd686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.61980538, 0.48133417,\n",
       "         0.61980538],\n",
       "        [0.63174505, 0.        , 0.        , 0.4804584 , 0.37311881,\n",
       "         0.4804584 ],\n",
       "        [0.        , 0.65249088, 0.65249088, 0.        , 0.38537163,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix = tfidf.fit_transform(text)\n",
    "sparse_matrix.todense()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
